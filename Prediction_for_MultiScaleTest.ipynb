{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.Mymodel import MyResNet34\n",
    "from src.Mymodel import MyResNet_CIFAR\n",
    "import tqdm\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms.v2 import (\n",
    "    ToTensor,\n",
    "    RandomHorizontalFlip,\n",
    "    Compose,\n",
    "    RandomCrop,\n",
    "    RandomShortestSize,\n",
    "    AutoAugment,\n",
    "    Normalize,\n",
    "    TenCrop,\n",
    "    CenterCrop,\n",
    "    Pad,\n",
    "    Resize,\n",
    "    Lambda\n",
    ")\n",
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "# DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Model selection for CIFAR\"\"\"\n",
    "NUM_LAYERS_LEVEL = 5\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 256\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "SPLIT_RATIO = 0\n",
    "\n",
    "\"\"\"optimizer parameters\"\"\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "# OPTIMIZER = \"Adam\"\n",
    "# OPTIMIZER = \"Adam_decay\"\n",
    "\n",
    "\"\"\"Learning rate scheduler parameters\"\"\"\n",
    "# LOAD_BEFORE_TRAINING = False\n",
    "LOAD_BEFORE_TRAINING = True\n",
    "NUM_EPOCHS = 1000\n",
    "scheduler_patience_mapping = {\"CIFAR10\": 100, \"CIFAR100\": 100, \"ImageNet2012\": 5}\n",
    "COOLDOWN = 10\n",
    "\n",
    "\"\"\"Early stopping parameters\"\"\"\n",
    "EARLYSTOPPINGPATIENCE = 30\n",
    "file_path = \"\"\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    file_path = f\"MyResNet34_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet34_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "    # casenum = 1\n",
    "    # if casenum != 0:\n",
    "    #     _model_name += f\"_case{casenum}\"\n",
    "else:\n",
    "    file_path = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "if SPLIT_RATIO != 0:\n",
    "    _model_name += f\"_{int(SPLIT_RATIO*100)}\"\n",
    "    file_path += f\"_{int(SPLIT_RATIO*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset:\n",
    "    def __init__(self, root, seceted_dataset, split_ratio=0):\n",
    "        self.Randp = 0.5\n",
    "        self.dataset_name = seceted_dataset\n",
    "        self.split_ratio = split_ratio\n",
    "\n",
    "        if self.dataset_name[:5] == \"CIFAR\":\n",
    "            pass\n",
    "\n",
    "        elif self.dataset_name == \"ImageNet2012\":\n",
    "            self.ImageNetRoot = root + \"/\" + self.dataset_name + \"/\"\n",
    "\n",
    "            \"\"\"\n",
    "            각 지정된 스케일에 따라 10 crop해야하는데, 5개 scale들의 평균을 내야하니까 좀 번거로움.\n",
    "            그치만, 학습 중엔 center crop으로 eval하니, 지금 당장 필요하지는 않음.\n",
    "            \"\"\"\n",
    "\n",
    "            test_data_list = list()\n",
    "            scales = [224, 256, 384, 480, 640]\n",
    "            for scale in scales:\n",
    "                test_data_list.append(\n",
    "                    datasets.ImageFolder(\n",
    "                        root=self.ImageNetRoot + \"val\",\n",
    "                        transform=Compose(\n",
    "                            [\n",
    "                                RandomShortestSize(min_size=scale + 1, antialias=True),\n",
    "                                TenCrop(size=scale),\n",
    "                                ToTensor(),\n",
    "                                Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[1, 1, 1],\n",
    "                                    inplace=True,\n",
    "                                ),\n",
    "                            ]\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            self.test_data_list = test_data_list\n",
    "            self.classes = 1000\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dataset: {self.dataset_name}\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tmp = LoadDataset(root=\"data\", seceted_dataset=DATASET)\n",
    "COUNT_OF_CLASSES = tmp.classes\n",
    "test_data = tmp.test_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_list = list()\n",
    "\n",
    "for i in range(5):\n",
    "    test_dataloader_list.append(\n",
    "        DataLoader(\n",
    "            test_data[i],\n",
    "            batch_size=BATCH,\n",
    "            shuffle=SHUFFLE,\n",
    "            # num_workers=NUMOFWORKERS,\n",
    "            # pin_memory=PIN_MEMORY,\n",
    "            # pin_memory_device=\"cuda\",\n",
    "            # persistent_workers=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/ImageNet2012/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "                 RandomShortestSize(min_size=[225], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "                 TenCrop(size=(224, 224), vertical_flip=False)\n",
      "                 ToTensor()\n",
      "                 Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/ImageNet2012/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "                 RandomShortestSize(min_size=[257], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "                 TenCrop(size=(256, 256), vertical_flip=False)\n",
      "                 ToTensor()\n",
      "                 Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/ImageNet2012/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "                 RandomShortestSize(min_size=[385], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "                 TenCrop(size=(384, 384), vertical_flip=False)\n",
      "                 ToTensor()\n",
      "                 Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/ImageNet2012/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "                 RandomShortestSize(min_size=[481], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "                 TenCrop(size=(480, 480), vertical_flip=False)\n",
      "                 ToTensor()\n",
      "                 Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data/ImageNet2012/val\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "                 RandomShortestSize(min_size=[641], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "                 TenCrop(size=(640, 640), vertical_flip=False)\n",
      "                 ToTensor()\n",
      "                 Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(test_dataloader_list[i].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-34 for ImageNet2012 is loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    model = MyResNet34(num_classes=COUNT_OF_CLASSES, Downsample_option=\"B\").to(device)\n",
    "    # model = models.resnet34(pretrained=True).to(device)\n",
    "    # model = models.resnet34(pretrained=False).to(device)\n",
    "    print(f\"ResNet-34 for {DATASET} is loaded.\")\n",
    "else:\n",
    "    model = MyResNet_CIFAR(\n",
    "        num_classes=COUNT_OF_CLASSES, num_layer_factor=NUM_LAYERS_LEVEL\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f\"models/{_model_name}/{file_path}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test0: 100%|██████████| 196/196 [10:03<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: Loss: 25.163187512937856, Top-1 Acc: 0.4722, Top-5 Acc: 0.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test1: 100%|██████████| 196/196 [11:19<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2: Loss: 23.189826230917657, Top-1 Acc: 0.50176, Top-5 Acc: 0.730776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test2: 100%|██████████| 196/196 [19:57<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3: Loss: 23.368813487948202, Top-1 Acc: 0.527296, Top-5 Acc: 0.75704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test3: 100%|██████████| 196/196 [28:12<00:00,  8.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 4: Loss: 26.610214240696966, Top-1 Acc: 0.496662, Top-5 Acc: 0.731202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test4: 100%|██████████| 196/196 [49:15<00:00, 15.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 5: Loss: 33.274302055032884, Top-1 Acc: 0.398678, Top-5 Acc: 0.637878\n",
      "Avg Loss: 26.321268705506714, Avg Top-1 Acc: 0.47931919999999995, Avg Top-5 Acc: 0.7118392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.eval()\n",
    "avg_loss = 0\n",
    "avg_top1_acc = 0\n",
    "avg_top5_acc = 0\n",
    "\n",
    "for i in range(5):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct_top1 = 0\n",
    "        correct_top5 = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm.tqdm(test_dataloader_list[i], desc=f\"test{i}\"):\n",
    "            for img in images:\n",
    "                img, labels = img.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Top-1 accuracy\n",
    "                _, predicted_top1 = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct_top1 += predicted_top1.eq(labels).sum().item()\n",
    "\n",
    "                # Top-5 accuracy\n",
    "                _, predicted_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "                correct_top5 += predicted_top5.eq(labels.view(-1, 1)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dataloader_list[i])\n",
    "        test_top1_acc = correct_top1 / total\n",
    "        test_top5_acc = correct_top5 / total\n",
    "\n",
    "        print(\n",
    "            f\"Dataset {i + 1}: Loss: {test_loss}, Top-1 Acc: {test_top1_acc}, Top-5 Acc: {test_top5_acc}\"\n",
    "        )\n",
    "\n",
    "        avg_loss += test_loss\n",
    "        avg_top1_acc += test_top1_acc\n",
    "        avg_top5_acc += test_top5_acc\n",
    "\n",
    "avg_loss /= 5\n",
    "avg_top1_acc /= 5\n",
    "avg_top5_acc /= 5\n",
    "\n",
    "print(\n",
    "    f\"Avg Loss: {avg_loss}, Avg Top-1 Acc: {avg_top1_acc}, Avg Top-5 Acc: {avg_top5_acc}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
