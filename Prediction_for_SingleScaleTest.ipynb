{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.Mymodel import MyResNet34\n",
    "from src.Mymodel import MyResNet_CIFAR\n",
    "from src.Mydataloader import LoadDataset\n",
    "from src.Mytraining import DoTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "# DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Model selection for CIFAR\"\"\"\n",
    "NUM_LAYERS_LEVEL = 5\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 256\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "SPLIT_RATIO = 0\n",
    "\n",
    "\"\"\"optimizer parameters\"\"\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "# OPTIMIZER = \"Adam\"\n",
    "# OPTIMIZER = \"Adam_decay\"\n",
    "\n",
    "\n",
    "file_path = \"\"\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    file_path = f\"MyResNet34_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet34_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "    # casenum = 1\n",
    "    # if casenum != 0:\n",
    "    #     _model_name += f\"_case{casenum}\"\n",
    "else:\n",
    "    file_path = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "if SPLIT_RATIO != 0:\n",
    "    _model_name += f\"_{int(SPLIT_RATIO*100)}\"\n",
    "    file_path += f\"_{int(SPLIT_RATIO*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Dataset :  ImageNet2012\n",
      "- Length of Train Set :  1281167\n",
      "- Length of Valid Set :  50000\n",
      "- Count of Classes :  1000\n",
      "-----------------------------------------------------------------------\n",
      "valid.transforms = Compose(\n",
      "      RandomShortestSize(min_size=[256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479], interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
      "      CenterCrop(size=(368, 368))\n",
      "      ToTensor()\n",
      "      Normalize(mean=[0.485, 0.456, 0.406], std=[1, 1, 1], inplace=True)\n",
      ") 256\n"
     ]
    }
   ],
   "source": [
    "tmp = LoadDataset(root=\"data\", seceted_dataset=DATASET, split_ratio=SPLIT_RATIO)\n",
    "_, valid_data, test_data, COUNT_OF_CLASSES = tmp.Unpack()\n",
    "\n",
    "if valid_data is not None:\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data,\n",
    "        batch_size=BATCH,\n",
    "        shuffle=SHUFFLE,\n",
    "        num_workers=NUMOFWORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        # pin_memory_device=\"cuda\",\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    print(\"valid.transforms =\", valid_data.transform, valid_dataloader.batch_size)\n",
    "else:\n",
    "    valid_dataloader = None\n",
    "\n",
    "if test_data is not None:\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=BATCH,\n",
    "        shuffle=SHUFFLE,\n",
    "        num_workers=NUMOFWORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        # pin_memory_device=\"cuda\",\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "    print(\"test.transforms =\", test_data.transform, test_dataloader.batch_size)\n",
    "else:\n",
    "    test_dataloader = None\n",
    "    \n",
    "\"\"\"Model selection\"\"\"   \n",
    "if valid_dataloader is None:\n",
    "    eval_dataloader = test_dataloader\n",
    "elif test_dataloader is None:\n",
    "    eval_dataloader = valid_dataloader\n",
    "else:\n",
    "    raise ValueError(\"valid_dataloader and test_dataloader cannot be None at the same time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    model = MyResNet34(num_classes=COUNT_OF_CLASSES, Downsample_option=\"B\").to(device)\n",
    "\n",
    "else:\n",
    "    model = MyResNet_CIFAR(\n",
    "        num_classes=COUNT_OF_CLASSES, num_layer_factor=NUM_LAYERS_LEVEL\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f\"models/{_model_name}/{file_path}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 196/196 [01:14<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "testingclass = DoTraining(\n",
    "    model=model, criterion=nn.CrossEntropyLoss(), optimizer=None, device=device\n",
    ")\n",
    "test_loss, test_acc = testingclass.Forward_eval(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 1.2982161787091469\n"
     ]
    }
   ],
   "source": [
    "print(\"test_loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 72.40%\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_acc: {test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error: 27.60%\n"
     ]
    }
   ],
   "source": [
    "print(f\"test_error: {100 - test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MyResNet34_256_SGD'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
