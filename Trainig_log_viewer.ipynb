{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.LogViewer import LogViewer\n",
    "from src.Earlystopper import EarlyStopper\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from src.Mymodel import MyResNet34\n",
    "from src.Mymodel import MyResNet_CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "# DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Model selection for CIFAR\"\"\"\n",
    "NUM_LAYERS_LEVEL = 5\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 256\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "SPLIT_RATIO = 0\n",
    "\n",
    "\"\"\"optimizer parameters\"\"\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "# OPTIMIZER = \"Adam\"\n",
    "# OPTIMIZER = \"Adam_decay\"\n",
    "\n",
    "\n",
    "file_path = \"\"\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    file_path = f\"MyResNet34_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet34_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "else:\n",
    "    file_path = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "if SPLIT_RATIO != 0:\n",
    "    _model_name += f\"_{int(SPLIT_RATIO*100)}\"\n",
    "    file_path += f\"_{int(SPLIT_RATIO*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\n",
    "    \"models/\"+_model_name+\"/\"+file_path + \".pth.tar\",\n",
    "    map_location=lambda storage, loc: storage.cuda(\"cuda\"),\n",
    ")\n",
    "\n",
    "logs = checkpoint[\"logs\"]\n",
    "\n",
    "print(\"Suceessfully loaded the All setting and Log file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATASET == \"CIFAR10\" or DATASET == \"CIFAR100\":\n",
    "    \"\"\"ResNet{20, 32, 44, 56, 110, 1202} for CIFAR\"\"\"\n",
    "    model = MyResNet_CIFAR(\n",
    "        num_classes=10,\n",
    "        num_layer_factor=NUM_LAYERS_LEVEL,\n",
    "        Downsample_option=\"A\",\n",
    "    ).to(\"cuda\")\n",
    "    print(f\"ResNet-{5*6+2} for {DATASET} is loaded.\")\n",
    "\n",
    "elif DATASET == \"ImageNet2012\":\n",
    "    \"\"\"ResNet34 for ImageNet 2012\"\"\"\n",
    "    model = MyResNet34(num_classes=1000, Downsample_option=\"B\").to(\"cuda\")\n",
    "    # model = models.resnet34(pretrained=True).to(device)\n",
    "    # model = models.resnet34(pretrained=False).to(device)\n",
    "    print(f\"ResNet-34 for {DATASET} is loaded.\")\n",
    "\n",
    "if OPTIMIZER == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "elif OPTIMIZER == \"Adam_decay\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "elif OPTIMIZER == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## (3) Define Early Stopping\n",
    "\n",
    "# %%\n",
    "earlystopper = EarlyStopper(\n",
    "    patience=777, model=model, file_path=file_path\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## (4) Define Learning Rate schedualer\n",
    "\n",
    "# %%\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    patience=777,\n",
    "    factor=0.1,\n",
    "    verbose=True,\n",
    "    threshold=1e-4,\n",
    "    cooldown=777,\n",
    ")\n",
    "\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "earlystopper.load_state_dict(checkpoint[\"earlystopper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"now lr:\", optimizer.param_groups[0][\"lr\"])\n",
    "print(\"earlystop counter:\", earlystopper.early_stop_counter)\n",
    "print(\"bad epoch counter:\", scheduler.num_bad_epochs)\n",
    "print(\"scheduler parience:\", scheduler.patience)\n",
    "print(\"scheduler cooldown counter:\", scheduler.cooldown_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = LogViewer(logs)\n",
    "# viewer.draw(start=4980, range=200)\n",
    "viewer.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.print_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.print_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주피터노트북 output set\n",
    "- @tag:notebookOutputLayout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
