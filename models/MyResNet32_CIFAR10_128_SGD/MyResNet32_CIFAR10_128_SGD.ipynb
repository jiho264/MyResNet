{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR, MultiStepLR\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(\"src\"))))\n",
    "\n",
    "from src.Mydataloader import LoadDataset\n",
    "from src.Mymodel import MyResNet_CIFAR\n",
    "from src.Mytraining import DoTraining\n",
    "from src.Earlystopper import EarlyStopper\n",
    "from src.LogViewer import LogViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "# DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 128\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 8\n",
    "PIN_MEMORY = True\n",
    "SPLIT_RATIO = 0\n",
    "\n",
    "\"\"\"optimizer parameters\"\"\"\n",
    "# OPTIMIZER = \"Adam\"\n",
    "# OPTIMIZER = \"Adam_decay\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "# OPTIMIZER = \"SGD_nasterov\"\n",
    "# OPTIMIZER = \"AdamW\"\n",
    "# OPTIMIZER = \"AdamW_amsgrad\"\n",
    "# OPTIMIZER = \"NAdam\"\n",
    "\n",
    "\"\"\"Learning rate scheduler parameters\"\"\"\n",
    "NUM_EPOCHS = 170\n",
    "\n",
    "\"\"\"Early stopping parameters\"\"\"\n",
    "EARLYSTOPPINGPATIENCE = 50\n",
    "\n",
    "file_name = f\"MyResNet32_{BATCH}_{OPTIMIZER}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MyResNet32_128_SGD'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dateloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Dataset :  CIFAR10\n",
      "- Length of Train Set :  50000\n",
      "- Length of Test Set :  10000\n",
      "- Count of Classes :  10\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "tmp = LoadDataset(root=\"../../data\", seceted_dataset=DATASET, split_ratio=SPLIT_RATIO)\n",
    "train_data, valid_data, test_data, COUNT_OF_CLASSES = tmp.Unpack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.transforms = Compose(\n",
      "      AutoAugment(interpolation=InterpolationMode.NEAREST, policy=AutoAugmentPolicy.CIFAR10)\n",
      "      RandomCrop(size=(32, 32), padding=[4, 4, 4, 4], pad_if_needed=False, fill=0, padding_mode=constant)\n",
      "      RandomHorizontalFlip(p=0.5)\n",
      "      ToTensor()\n",
      "      Normalize(mean=[0.49139968, 0.48215827, 0.44653124], std=[1, 1, 1], inplace=True)\n",
      ") 128\n",
      "test.transforms = ToTensor() 128\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = tmp.get_dataloader(\n",
    "    batch_size=BATCH, shuffle=SHUFFLE, num_workers=NUMOFWORKERS, pin_memory=PIN_MEMORY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyResNet_CIFAR(num_classes=COUNT_OF_CLASSES, num_layer_factor=5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Define Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Define Optimazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIMIZER == \"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "elif OPTIMIZER == \"Adam_decay\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "elif OPTIMIZER == \"SGD\":\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4\n",
    "    )\n",
    "elif OPTIMIZER == \"SGD_nasterov\":\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4, nesterov=True\n",
    "    )\n",
    "elif OPTIMIZER == \"AdamW\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-4)\n",
    "elif OPTIMIZER == \"AdamW_amsgrad\":\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-4, amsgrad=True)\n",
    "elif OPTIMIZER == \"NAdam\":\n",
    "    optimizer = torch.optim.NAdam(model.parameters(), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Define Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopper(patience=EARLYSTOPPINGPATIENCE, model=model, file_name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Define Learning Rate schedualer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n=======================================================\\nif batch = 256\\n=======================================================\\nnon-split [single epoch = 196 iter] : milestones = [164, 246]\\n- 1 ~ 164 epochs == 1 ~ 32k iter >> lr = 0.1\\n- 165~246 epochs == 32k ~ 48k iter >> lr = 0.01\\n- 247~328(?) epochs == 48k ~ 64k iter >> lr = 0.001\\n=======================================================\\nsplit to 45k/5k [single epoch = 176 iter]: milestones = [182, 273]\\n- 1~182 epochs == 1 ~ 32k iter >> lr = 0.1\\n- 182~273 epochs == 32k ~ 48k iter >> lr = 0.01\\n- 273~364(?) epochs == 48k ~ 64k iter >> lr = 0.001\\n=======================================================\\nif batch = 128\\n=======================================================\\nnon-split [signle epoch = 391 iter]: milestones = [82, 123]\\n- 1 ~ 82 epochs == 1 ~ 32k iter >> lr = 0.1\\n- 83~123 epochs == 32k ~ 48k iter >> lr = 0.01\\n- 124~(164) epochs == 48k ~ 64k iter >> lr = 0.001\\n=======================================================\\nsplit to 45k/5k [signle epoch = 352 iter]: milestones = [91, 137]\\n- 1~91 epochs == 1 ~ 32k iter >> lr = 0.1\\n- 92~137 epochs == 32k ~ 48k iter >> lr = 0.01\\n- 138~(183) epochs == 48k ~ 64k iter >> lr = 0.001\\n=======================================================\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scheduler = ExponentialLR(optimizer, gamma=0.95)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[82, 123], gamma=0.1)\n",
    "\"\"\"\n",
    "=======================================================\n",
    "if batch = 256\n",
    "=======================================================\n",
    "non-split [single epoch = 196 iter] : milestones = [164, 246]\n",
    "- 1 ~ 164 epochs == 1 ~ 32k iter >> lr = 0.1\n",
    "- 165~246 epochs == 32k ~ 48k iter >> lr = 0.01\n",
    "- 247~328(?) epochs == 48k ~ 64k iter >> lr = 0.001\n",
    "=======================================================\n",
    "split to 45k/5k [single epoch = 176 iter]: milestones = [182, 273]\n",
    "- 1~182 epochs == 1 ~ 32k iter >> lr = 0.1\n",
    "- 182~273 epochs == 32k ~ 48k iter >> lr = 0.01\n",
    "- 273~364(?) epochs == 48k ~ 64k iter >> lr = 0.001\n",
    "=======================================================\n",
    "if batch = 128\n",
    "=======================================================\n",
    "non-split [signle epoch = 391 iter]: milestones = [82, 123]\n",
    "- 1 ~ 82 epochs == 1 ~ 32k iter >> lr = 0.1\n",
    "- 83~123 epochs == 32k ~ 48k iter >> lr = 0.01\n",
    "- 124~(164) epochs == 48k ~ 64k iter >> lr = 0.001\n",
    "=======================================================\n",
    "split to 45k/5k [signle epoch = 352 iter]: milestones = [91, 137]\n",
    "- 1~91 epochs == 1 ~ 32k iter >> lr = 0.1\n",
    "- 92~137 epochs == 32k ~ 48k iter >> lr = 0.01\n",
    "- 138~(183) epochs == 48k ~ 64k iter >> lr = 0.001\n",
    "=======================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Define AMP scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler(enabled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load before process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist. Created a new log.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(file_name + \".pth.tar\"):\n",
    "    # Read checkpoint as desired, e.g.,\n",
    "    checkpoint = torch.load(\n",
    "        file_name + \".pth.tar\",\n",
    "        map_location=lambda storage, loc: storage.cuda(device),\n",
    "    )\n",
    "    model.load_state_dict(checkpoint[\"model\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    scaler.load_state_dict(checkpoint[\"scaler\"])\n",
    "    scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "    earlystopper.load_state_dict(checkpoint[\"earlystopper\"])\n",
    "    logs = checkpoint[\"logs\"]\n",
    "\n",
    "    print(\"Suceessfully loaded the All setting and Log file.\")\n",
    "    print(file_name)\n",
    "    print(f\"Current epoch is {len(logs['train_loss'])}\")\n",
    "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "else:\n",
    "    # Create a dictionary to store the variables\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    eval_loss = []\n",
    "    valid_acc = []\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    lr_log = []\n",
    "    logs = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"valid_loss\": eval_loss,\n",
    "        \"valid_acc\": valid_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"lr_log\": lr_log,\n",
    "    }\n",
    "    print(\"File does not exist. Created a new log.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopper.early_stop_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Training Loop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 Train: 100%|███████| 391/391 [00:43<00:00,  8.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3932 | Train Acc: 13.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  Loss: 2.1028 | Test Acc: 20.90%\n",
      "updated best eval loss : 2.1027612731426575\n",
      "--------------------------------------------------\n",
      "[Epoch 2/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2 Train: 100%|███████| 391/391 [00:45<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0268 | Train Acc: 23.89%\n",
      "Test  Loss: 2.0168 | Test Acc: 23.93%\n",
      "updated best eval loss : 2.016815063319629\n",
      "--------------------------------------------------\n",
      "[Epoch 3/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 Train: 100%|███████| 391/391 [00:46<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6615 | Train Acc: 39.21%\n",
      "Test  Loss: 2.0925 | Test Acc: 33.68%\n",
      "--------------------------------------------------\n",
      "[Epoch 4/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4 Train: 100%|███████| 391/391 [00:35<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2924 | Train Acc: 54.15%\n",
      "Test  Loss: 1.3787 | Test Acc: 52.33%\n",
      "updated best eval loss : 1.3787231264235098\n",
      "--------------------------------------------------\n",
      "[Epoch 5/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5 Train: 100%|███████| 391/391 [00:34<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0865 | Train Acc: 61.81%\n",
      "Test  Loss: 1.9567 | Test Acc: 42.03%\n",
      "--------------------------------------------------\n",
      "[Epoch 6/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6 Train: 100%|███████| 391/391 [00:33<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9804 | Train Acc: 65.72%\n",
      "Test  Loss: 1.4186 | Test Acc: 54.76%\n",
      "--------------------------------------------------\n",
      "[Epoch 7/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7 Train: 100%|███████| 391/391 [00:32<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9106 | Train Acc: 68.22%\n",
      "Test  Loss: 1.8498 | Test Acc: 47.38%\n",
      "--------------------------------------------------\n",
      "[Epoch 8/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8 Train: 100%|███████| 391/391 [00:32<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8484 | Train Acc: 70.56%\n",
      "Test  Loss: 0.9311 | Test Acc: 68.36%\n",
      "updated best eval loss : 0.9310874825791468\n",
      "--------------------------------------------------\n",
      "[Epoch 9/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9 Train: 100%|███████| 391/391 [00:34<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8104 | Train Acc: 71.78%\n",
      "Test  Loss: 1.3588 | Test Acc: 57.01%\n",
      "--------------------------------------------------\n",
      "[Epoch 10/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 Train: 100%|██████| 391/391 [00:33<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7740 | Train Acc: 73.13%\n",
      "Test  Loss: 1.1262 | Test Acc: 63.70%\n",
      "--------------------------------------------------\n",
      "[Epoch 11/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11 Train: 100%|██████| 391/391 [00:33<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7525 | Train Acc: 73.73%\n",
      "Test  Loss: 1.0131 | Test Acc: 66.52%\n",
      "--------------------------------------------------\n",
      "[Epoch 12/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Train: 100%|██████| 391/391 [00:33<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7250 | Train Acc: 74.83%\n",
      "Test  Loss: 1.6305 | Test Acc: 55.28%\n",
      "--------------------------------------------------\n",
      "[Epoch 13/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 Train: 100%|██████| 391/391 [00:33<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7004 | Train Acc: 75.65%\n",
      "Test  Loss: 1.0730 | Test Acc: 65.78%\n",
      "--------------------------------------------------\n",
      "[Epoch 14/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Train: 100%|██████| 391/391 [00:35<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6854 | Train Acc: 76.02%\n",
      "Test  Loss: 0.9337 | Test Acc: 68.77%\n",
      "--------------------------------------------------\n",
      "[Epoch 15/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15 Train: 100%|██████| 391/391 [00:48<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6676 | Train Acc: 76.83%\n",
      "Test  Loss: 0.9890 | Test Acc: 66.95%\n",
      "--------------------------------------------------\n",
      "[Epoch 16/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 Train: 100%|██████| 391/391 [00:45<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6507 | Train Acc: 77.67%\n",
      "Test  Loss: 1.0316 | Test Acc: 67.76%\n",
      "--------------------------------------------------\n",
      "[Epoch 17/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17 Train: 100%|██████| 391/391 [00:48<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6447 | Train Acc: 77.80%\n",
      "Test  Loss: 0.8529 | Test Acc: 71.45%\n",
      "updated best eval loss : 0.8529078251198877\n",
      "--------------------------------------------------\n",
      "[Epoch 18/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18 Train: 100%|██████| 391/391 [00:46<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6302 | Train Acc: 78.36%\n",
      "Test  Loss: 0.8800 | Test Acc: 70.95%\n",
      "--------------------------------------------------\n",
      "[Epoch 19/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19 Train: 100%|██████| 391/391 [00:47<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6202 | Train Acc: 78.44%\n",
      "Test  Loss: 0.6774 | Test Acc: 76.98%\n",
      "updated best eval loss : 0.6774449367311937\n",
      "--------------------------------------------------\n",
      "[Epoch 20/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20 Train: 100%|██████| 391/391 [00:46<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6118 | Train Acc: 78.83%\n",
      "Test  Loss: 0.7915 | Test Acc: 73.51%\n",
      "--------------------------------------------------\n",
      "[Epoch 21/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Train: 100%|██████| 391/391 [00:47<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6094 | Train Acc: 78.83%\n",
      "Test  Loss: 1.0809 | Test Acc: 66.44%\n",
      "--------------------------------------------------\n",
      "[Epoch 22/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22 Train: 100%|██████| 391/391 [00:46<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5900 | Train Acc: 79.53%\n",
      "Test  Loss: 0.7649 | Test Acc: 74.03%\n",
      "--------------------------------------------------\n",
      "[Epoch 23/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23 Train: 100%|██████| 391/391 [00:48<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5834 | Train Acc: 79.84%\n",
      "Test  Loss: 0.7804 | Test Acc: 72.65%\n",
      "--------------------------------------------------\n",
      "[Epoch 24/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24 Train: 100%|██████| 391/391 [00:45<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5844 | Train Acc: 79.73%\n",
      "Test  Loss: 0.7412 | Test Acc: 75.34%\n",
      "--------------------------------------------------\n",
      "[Epoch 25/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25 Train: 100%|██████| 391/391 [00:48<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5712 | Train Acc: 80.10%\n",
      "Test  Loss: 1.1093 | Test Acc: 65.15%\n",
      "--------------------------------------------------\n",
      "[Epoch 26/170] :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26 Train:  55%|███▎  | 214/391 [00:25<00:23,  7.55it/s]"
     ]
    }
   ],
   "source": [
    "Training = DoTraining(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    scheduler=scheduler,\n",
    "    earlystopper=earlystopper,\n",
    "    device=device,\n",
    "    logs=logs,\n",
    "    file_path=file_name,\n",
    ")\n",
    "pre_epochs = len(Training.logs[\"train_loss\"])\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    now = epoch + 1 + pre_epochs\n",
    "    print(f\"[Epoch {epoch+1+pre_epochs}/{NUM_EPOCHS}] :\")\n",
    "\n",
    "    if DATASET == \"ImageNet2012\":\n",
    "        eval_loss = Training.SingleEpoch(train_dataloader, valid_dataloader)\n",
    "    else:\n",
    "        eval_loss = Training.SingleEpoch(\n",
    "            train_dataloader, valid_dataloader, test_dataloader\n",
    "        )\n",
    "\n",
    "    Training.Save()\n",
    "\n",
    "    \n",
    "    \n",
    "    if earlystopper.check(eval_loss) == True:\n",
    "        break\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = LogViewer(logs)\n",
    "view.draw(save_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.print_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
