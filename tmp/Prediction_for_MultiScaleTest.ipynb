{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from src.Mymodel import MyResNet34\n",
    "from src.Mymodel import MyResNet_CIFAR\n",
    "import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms.v2 import (\n",
    "    ToTensor,\n",
    "    Compose,\n",
    "    RandomShortestSize,\n",
    "    Normalize,\n",
    "    TenCrop,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset selection\"\"\"\n",
    "# DATASET = \"CIFAR10\"\n",
    "# DATASET = \"CIFAR100\"\n",
    "DATASET = \"ImageNet2012\"\n",
    "\n",
    "\"\"\"Model selection for CIFAR\"\"\"\n",
    "NUM_LAYERS_LEVEL = 5\n",
    "\n",
    "\"\"\"Dataset parameters\"\"\"\n",
    "BATCH = 256\n",
    "SHUFFLE = True\n",
    "NUMOFWORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "SPLIT_RATIO = 0\n",
    "\n",
    "\"\"\"optimizer parameters\"\"\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "# OPTIMIZER = \"Adam\"\n",
    "# OPTIMIZER = \"Adam_decay\"\n",
    "\n",
    "\n",
    "file_path = \"\"\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    file_path = f\"MyResNet34_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet34_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "else:\n",
    "    file_path = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{BATCH}_{OPTIMIZER}\"\n",
    "    _model_name = f\"MyResNet{NUM_LAYERS_LEVEL*6+2}_{DATASET}_{BATCH}_{OPTIMIZER}\"\n",
    "\n",
    "if SPLIT_RATIO != 0:\n",
    "    _model_name += f\"_{int(SPLIT_RATIO*100)}\"\n",
    "    file_path += f\"_{int(SPLIT_RATIO*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset:\n",
    "    def __init__(self, root, seceted_dataset):\n",
    "        self.dataset_name = seceted_dataset\n",
    "\n",
    "        if self.dataset_name[:5] == \"CIFAR\":\n",
    "            pass\n",
    "\n",
    "        elif self.dataset_name == \"ImageNet2012\":\n",
    "            self.ImageNetRoot = root + \"/\" + self.dataset_name + \"/\"\n",
    "\n",
    "            \"\"\"\n",
    "            각 지정된 스케일에 따라 10 crop해야하는데, 5개 scale들의 평균을 내야하니까 좀 번거로움.\n",
    "            그치만, 학습 중엔 center crop으로 eval하니, 지금 당장 필요하지는 않음.\n",
    "            \"\"\"\n",
    "\n",
    "            test_data_list = list()\n",
    "            scales = [224, 256, 384, 480, 640]\n",
    "            # scales = [640, 480, 384, 256, 224]\n",
    "            for scale in scales:\n",
    "                test_data_list.append(\n",
    "                    datasets.ImageFolder(\n",
    "                        root=self.ImageNetRoot + \"val\",\n",
    "                        transform=Compose(\n",
    "                            [\n",
    "                                RandomShortestSize(min_size=scale + 1, antialias=True),\n",
    "                                TenCrop(size=scale),\n",
    "                                ToTensor(),\n",
    "                                Normalize(\n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[1, 1, 1],\n",
    "                                    inplace=True,\n",
    "                                ),\n",
    "                            ]\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "            self.test_data_list = test_data_list\n",
    "            self.classes = 1000\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported dataset: {self.dataset_name}\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lee/anaconda3/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tmp = LoadDataset(root=\"data\", seceted_dataset=DATASET)\n",
    "COUNT_OF_CLASSES = tmp.classes\n",
    "test_data = tmp.test_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redirect the output to a file\n",
    "sys.stdout = open(f\"MultiScaleTestLog_{DATASET}_{BATCH}_{OPTIMIZER}.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_list = list()\n",
    "batch_size_list = [256, 128, 96, 64, 28]\n",
    "num_workers_list = [8, 8, 8, 8, 8]\n",
    "for i in range(5):\n",
    "    test_dataloader_list.append(\n",
    "        DataLoader(\n",
    "            test_data[i],\n",
    "            batch_size=batch_size_list[i],\n",
    "            shuffle=SHUFFLE,\n",
    "            num_workers=num_workers_list[i],\n",
    "            # pin_memory=PIN_MEMORY,\n",
    "            # pin_memory_device=\"cuda\",\n",
    "            # persistent_workers=True,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        test_dataloader_list[i].dataset,\n",
    "        len(test_dataloader_list[i]),\n",
    "        len(test_dataloader_list[i].dataset),\n",
    "        test_dataloader_list[i].batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if DATASET == \"ImageNet2012\":\n",
    "    model = MyResNet34(num_classes=COUNT_OF_CLASSES, Downsample_option=\"B\").to(device)\n",
    "    # model = models.resnet34(pretrained=True).to(device)\n",
    "    # model = models.resnet34(pretrained=False).to(device)\n",
    "    print(f\"ResNet-34 for {DATASET} is loaded.\")\n",
    "else:\n",
    "    model = MyResNet_CIFAR(\n",
    "        num_classes=COUNT_OF_CLASSES, num_layer_factor=NUM_LAYERS_LEVEL\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(f\"models/{_model_name}/{file_path}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test0:  81%|████████  | 158/196 [03:38<00:52,  1.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(img)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 21\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Top-1 accuracy\u001b[39;00m\n\u001b[1;32m     24\u001b[0m _, predicted_top1 \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.eval()\n",
    "avg_loss = 0\n",
    "avg_top1_acc = 0\n",
    "avg_top5_acc = 0\n",
    "\n",
    "for i in range(5):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        correct_top1 = 0\n",
    "        correct_top5 = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm.tqdm(test_dataloader_list[i], desc=f\"test{i}\"):\n",
    "            for img in images:\n",
    "                img, labels = img.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(img)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Top-1 accuracy\n",
    "                _, predicted_top1 = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct_top1 += predicted_top1.eq(labels).sum().item()\n",
    "\n",
    "                # Top-5 accuracy\n",
    "                _, predicted_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "                correct_top5 += predicted_top5.eq(labels.view(-1, 1)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_dataloader_list[i])\n",
    "        test_top1_acc = correct_top1 / total\n",
    "        test_top5_acc = correct_top5 / total\n",
    "\n",
    "        print(\n",
    "            f\"Dataset {i + 1}: Loss: {test_loss}, Top-1 Acc: {test_top1_acc}, Top-5 Acc: {test_top5_acc}\"\n",
    "        )\n",
    "\n",
    "        avg_loss += test_loss\n",
    "        avg_top1_acc += test_top1_acc\n",
    "        avg_top5_acc += test_top5_acc\n",
    "\n",
    "avg_loss /= 5\n",
    "avg_top1_acc /= 5\n",
    "avg_top5_acc /= 5\n",
    "\n",
    "print(\n",
    "    f\"Avg Loss: {avg_loss}, Avg Top-1 Acc: {avg_top1_acc}, Avg Top-5 Acc: {avg_top5_acc}\"\n",
    ")\n",
    "\n",
    "# Close the file\n",
    "sys.stdout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
